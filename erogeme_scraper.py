# erogeme_scraper.py
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import os
from openpyxl import load_workbook

# è¨­å®š
url_file = "urls.txt"
output_file = "erogame_stats.xlsx"

# URLä¸€è¦§èª­ã¿è¾¼ã¿
with open(url_file, "r", encoding="utf-8") as f:
    urls = [line.strip() for line in f if line.strip()]

# çµæœãƒªã‚¹ãƒˆ
results = []

# å„URLã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
for url in urls:
    try:
        res = requests.get(url, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")

        title_tag = soup.select_one("div#soft-title span.bold")
        title = title_tag.text.strip() if title_tag else "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜"

        brand_tag = soup.select_one("tr#brand td a")
        brand = brand_tag.text.strip() if brand_tag else "ãƒ–ãƒ©ãƒ³ãƒ‰ä¸æ˜"

        median = average = max_score = min_score = None

        for row in soup.select("tr"):
            th = row.find("th")
            td = row.find("td")
            if not th or not td:
                continue
            key = th.text.strip()
            val = td.text.strip()
            if key == "ä¸­å¤®å€¤":
                median = int(val)
            elif key == "å¹³å‡å€¤":
                average = int(val)
            elif key == "æœ€é«˜ç‚¹":
                max_score = int(val)
            elif key == "æœ€ä½ç‚¹":
                min_score = int(val)

        results.append({
            "å–å¾—æ—¥æ™‚": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "ã‚¿ã‚¤ãƒˆãƒ«": title,
            "ãƒ–ãƒ©ãƒ³ãƒ‰": brand,
            "ä¸­å¤®å€¤": median,
            "å¹³å‡å€¤": average,
            "æœ€é«˜ç‚¹": max_score,
            "æœ€ä½ç‚¹": min_score,
            "URL": url
        })

        print(f"âœ… å–å¾—æˆåŠŸï¼š{title}")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ï¼š{url}")
        print(e)

# çµ±è¨ˆå‡¦ç†
medians = [r["ä¸­å¤®å€¤"] for r in results if r["ä¸­å¤®å€¤"] is not None]
mean_median = sum(medians) / len(medians)
std_median = pd.Series(medians).std()

# åå·®å€¤è¨ˆç®—
for r in results:
    median = r["ä¸­å¤®å€¤"]
    if isinstance(median, int) and std_median != 0:
        r["ä¸­å¤®å€¤åå·®å€¤"] = round((median - mean_median) / std_median * 10 + 50, 2)
    else:
        r["ä¸­å¤®å€¤åå·®å€¤"] = None

# åˆ—ã®é †åº
columns_order = [
    "å–å¾—æ—¥æ™‚", "ã‚¿ã‚¤ãƒˆãƒ«", "ãƒ–ãƒ©ãƒ³ãƒ‰", "ä¸­å¤®å€¤", "å¹³å‡å€¤", "æœ€é«˜ç‚¹", "æœ€ä½ç‚¹", "ä¸­å¤®å€¤åå·®å€¤", "URL"
]

# Excelãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
if os.path.exists(output_file):
    try:
        os.remove(output_file)
    except Exception as e:
        print("âš ï¸ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        raise e

# DataFrameå‡ºåŠ›
df = pd.DataFrame(results)[columns_order]
df.to_excel(output_file, index=False)

# åˆ—å¹…èª¿æ•´
wb = load_workbook(output_file)
ws = wb.active

column_widths = {
    "A": 19, "B": 45, "C": 20, "D": 8, "E": 8,
    "F": 8, "G": 8, "H": 12, "I": 70
}
for col, width in column_widths.items():
    ws.column_dimensions[col].width = width

# ä¸­å¤®å€¤ã®æ¨™æº–åå·®ã‚’ä¸‹éƒ¨ã«è¡¨ç¤º
last_row = ws.max_row + 2
ws[f"A{last_row}"] = "ä¸­å¤®å€¤ã®æ¨™æº–åå·®"
ws[f"B{last_row}"] = round(std_median, 2)

# ä¿å­˜
wb.save(output_file)

print(f"\nğŸ“ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº† â†’ {output_file}")
